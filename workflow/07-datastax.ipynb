{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from astrapy import DataAPIClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get API key and URL from environment variables\n",
    "ASTRA_TOKEN = os.getenv('ASTRA_TOKEN')\n",
    "ASTRA_API_ENDPOINT = os.getenv('ASTRA_API_ENDPOINT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to a database\n",
    "client = DataAPIClient(ASTRA_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = client.get_database(ASTRA_API_ENDPOINT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASTRA_TOKEN: AstraCS:EtDeDieMsPARStKtcnZOFOdY:3f802e2e07da5be014ce2a3d26dcc8693c8acde7dd35dbe1df384624f83397d3\n",
      "ASTRA_API_ENDPOINT: https://2534174f-90b3-4e11-afb5-8ee29c3c090d-us-east-2.apps.astra.datastax.com\n"
     ]
    }
   ],
   "source": [
    "print(f\"ASTRA_TOKEN: {ASTRA_TOKEN}\")\n",
    "print(f\"ASTRA_API_ENDPOINT: {ASTRA_API_ENDPOINT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connected to Astra DB: []\n"
     ]
    }
   ],
   "source": [
    "print(f\"Connected to Astra DB: {database.list_collection_names()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collection 'HolocaustTestimonies' created successfully.\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"HolocaustTestimonies\"\n",
    "\n",
    "\n",
    "# Create or get the collection\n",
    "collection = database.create_collection(collection_name, dimension=768)\n",
    "\n",
    "# Define the schema\n",
    "schema = {\n",
    "    \"sentence_ids\": \"list<text>\",\n",
    "    \"text\": \"text\",\n",
    "    \"category\": \"text\",\n",
    "    \"populated_place\": \"int\",\n",
    "    \"building\": \"int\",\n",
    "    \"country\": \"int\",\n",
    "    \"spatial_obj\": \"int\",\n",
    "    \"dlf\": \"int\",\n",
    "    \"int_space\": \"int\",\n",
    "    \"env_features\": \"int\",\n",
    "    \"region\": \"int\",\n",
    "    \"npip\": \"int\",\n",
    "    \"experience_group\": \"text\",\n",
    "    \"birth_country\": \"text\",\n",
    "    \"gender\": \"text\",\n",
    "    \"rg\": \"text\",\n",
    "    \"full_name\": \"text\",\n",
    "    \"birth_year\": \"int\"\n",
    "}\n",
    "\n",
    "print(f\"Collection '{collection_name}' created successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4 parquet files.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Preparing data: 100%|██████████| 1050/1050 [00:00<00:00, 24661.32it/s]\n",
      "Inserting data: 100%|██████████| 11/11 [00:09<00:00,  1.16it/s]\n",
      "Preparing data: 100%|██████████| 1824/1824 [00:00<00:00, 24153.75it/s]\n",
      "Inserting data: 100%|██████████| 19/19 [00:16<00:00,  1.13it/s]\n",
      "Preparing data: 100%|██████████| 1625/1625 [00:00<00:00, 22100.05it/s]\n",
      "Inserting data: 100%|██████████| 17/17 [00:14<00:00,  1.14it/s]\n",
      "Preparing data: 100%|██████████| 808/808 [00:00<00:00, 24856.23it/s]\n",
      "Inserting data: 100%|██████████| 9/9 [00:07<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data insertion complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get list of parquet files\n",
    "parquet_files = glob.glob(\"../data/06_parquet/*.parquet\")\n",
    "parquet_files.sort()\n",
    "parquet_files = parquet_files[:4]\n",
    "print(f\"Found {len(parquet_files)} parquet files.\")\n",
    "\n",
    "# Function to prepare a single row\n",
    "def prepare_row(row):\n",
    "    def safe_int(value):\n",
    "        return int(value) if value is not None else 0\n",
    "\n",
    "    return {\n",
    "        \"sentence_ids\": row['sentence_ids'].tolist() if isinstance(row['sentence_ids'], np.ndarray) else row['sentence_ids'],\n",
    "        \"text\": row['text'],\n",
    "        \"category\": row['category'],\n",
    "        \"populated_place\": safe_int(row['populated_place']),\n",
    "        \"building\": safe_int(row['building']),\n",
    "        \"country\": safe_int(row['country']),\n",
    "        \"spatial_obj\": safe_int(row['spatial_obj']),\n",
    "        \"dlf\": safe_int(row['dlf']),\n",
    "        \"int_space\": safe_int(row['int_space']),\n",
    "        \"env_features\": safe_int(row['env_features']),\n",
    "        \"region\": safe_int(row['region']),\n",
    "        \"npip\": safe_int(row['npip']),\n",
    "        \"experience_group\": row['experience_group'],\n",
    "        \"birth_country\": row['birth_country'],\n",
    "        \"gender\": row['gender'],\n",
    "        \"rg\": row['rg'],\n",
    "        \"full_name\": row['full_name'],\n",
    "        \"birth_year\": safe_int(row['birth_year']),\n",
    "        \"$vector\": row['embedding'].tolist() if isinstance(row['embedding'], np.ndarray) else row['embedding']\n",
    "    }\n",
    "\n",
    "# Process each parquet file\n",
    "for parquet_file in parquet_files:\n",
    "    df = pd.read_parquet(parquet_file)\n",
    "    \n",
    "    data_rows = []\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Preparing data\"):\n",
    "        data_rows.append(prepare_row(row))\n",
    "    \n",
    "    # Perform batch insertion\n",
    "    for i in tqdm(range(0, len(data_rows), 100), desc=\"Inserting data\"):\n",
    "        batch = data_rows[i:i+100]\n",
    "        collection.insert_many(documents=batch)\n",
    "\n",
    "print(\"Data insertion complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/envs/fasthtml/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm, trange\n",
      "/Applications/anaconda3/envs/fasthtml/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "/Applications/anaconda3/envs/fasthtml/lib/python3.10/site-packages/sentence_transformers/models/Dense.py:89: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  torch.load(os.path.join(input_path, \"pytorch_model.bin\"), map_location=torch.device(\"cpu\"))\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "model = SentenceTransformer('sentence-transformers/LaBSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 results for the query 'Hunger':\n",
      "1. Text: A: I very often was very hungry, but what I remember most is thirst, always being thirsty and never having enough to drink.  I think at one point I sort of lost my appetite for food except when you know you have a grumbling stomach, but I didn't know really.  I was scared. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "\n",
      "2. Text: A: Well, there was starvation, and the worst thing there was no water.  We were hiding in basements.  It was really mayhem. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "\n",
      "3. Text: A: Well, there was starvation, and the worst thing there was no water.  We were hiding in basements.  It was really mayhem. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "\n",
      "4. Text: I think at one point I sort of lost my appetite for food except when you know you have a grumbling stomach, but I didn't know really.  I was scared.  I was always full of fear and hunger doesn't always assert itself when you're full of fear. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "\n",
      "5. Text: I was always full of fear and hunger doesn't always assert itself when you're full of fear.  Yes, I remember times that I was hungry, but not so much hungry as full of fear and very thirsty always.  There was never enough to drink. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the collection with the phrase \"Hunger\"\n",
    "query_text = \"Hunger\"\n",
    "\n",
    "# Encode the query text\n",
    "query_embedding = model.encode(query_text)\n",
    "\n",
    "# Perform the vector search\n",
    "search_results = collection.find(\n",
    "    filter={},\n",
    "    sort={\"$vector\": query_embedding},\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(f\"Top 5 results for the query '{query_text}':\")\n",
    "for i, doc in enumerate(search_results, 1):\n",
    "    print(f\"{i}. Text: {doc['text']}\")\n",
    "    print(f\"   Category: {doc['category']}\")\n",
    "    print(f\"   Experience Group: {doc['experience_group']}\")\n",
    "    print()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': 'ef2dacf0-f88e-420f-adac-f0f88ee20f4a',\n",
       " 'sentence_ids': ['2339', '2340'],\n",
       " 'text': \"Q: You're tired aren't you.  Do you want to stop? \",\n",
       " 'category': 'question',\n",
       " 'populated_place': 0,\n",
       " 'building': 0,\n",
       " 'country': 0,\n",
       " 'spatial_obj': 0,\n",
       " 'dlf': 0,\n",
       " 'int_space': 0,\n",
       " 'env_features': 0,\n",
       " 'region': 0,\n",
       " 'npip': 0,\n",
       " 'experience_group': 'survivor',\n",
       " 'birth_country': 'poland',\n",
       " 'gender': 'm',\n",
       " 'rg': 'rg-50.030.0001',\n",
       " 'full_name': 'david a. kochalski',\n",
       " 'birth_year': 1928}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 results for the query 'Wir hatten keine essen' with filters:\n",
      "1. Text: I don't even know if there was anything to drink.  We all had something to eat, I mean whatever we grabbed.  As I said, we had an extra bread which we never allowed ourselves to eat the whole bread. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "   Populated Place: 0\n",
      "   Birth Country: poland\n",
      "\n",
      "2. Text: Food, they took away.  So we went three days and we didn't eat because there was no food in Germany no where.  We went through Nuremberg. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "   Populated Place: 0\n",
      "   Birth Country: hungary\n",
      "\n",
      "3. Text: So at least I had money.  Food, they took away.  So we went three days and we didn't eat because there was no food in Germany no where. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "   Populated Place: 0\n",
      "   Birth Country: hungary\n",
      "\n",
      "4. Text: We used to - - we didn't have any horses or anything, we used to have a little buggy, long buggy, one on the side and I on other side and we would pull from place to place and distribute food.  This I got so many bread.  That was my first job. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "   Populated Place: 0\n",
      "   Birth Country: poland\n",
      "\n",
      "5. Text: We used to - - we didn't have any horses or anything, we used to have a little buggy, long buggy, one on the side and I on other side and we would pull from place to place and distribute food.  This I got so many bread.  That was my first job. \n",
      "   Category: answer\n",
      "   Experience Group: survivor\n",
      "   Populated Place: 0\n",
      "   Birth Country: poland\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the collection with the phrase \"Hunger\" and additional filters\n",
    "query_text = \"Wir hatten keine essen\"\n",
    "\n",
    "# Encode the query text\n",
    "query_embedding = model.encode(query_text)\n",
    "\n",
    "# Perform the vector search with filters\n",
    "search_results = collection.find(\n",
    "    filter={\n",
    "        # \"building\": {\"$gt\": 0},\n",
    "        # \"birth_country\": \"poland\"\n",
    "    },\n",
    "    sort={\"$vector\": query_embedding},\n",
    "    limit=5\n",
    ")\n",
    "\n",
    "print(f\"Top 5 results for the query '{query_text}' with filters:\")\n",
    "for i, doc in enumerate(search_results, 1):\n",
    "    print(f\"{i}. Text: {doc['text']}\")\n",
    "    print(f\"   Category: {doc['category']}\")\n",
    "    print(f\"   Experience Group: {doc['experience_group']}\")\n",
    "    print(f\"   Populated Place: {doc['populated_place']}\")\n",
    "    print(f\"   Birth Country: {doc['birth_country']}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fasthtml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
